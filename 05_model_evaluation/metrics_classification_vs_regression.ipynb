{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4BtmkPJh3Bvb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 📏 Evaluación de Modelos: Clasificación vs Regresión\n",
        "\n",
        "Este notebook resume y ejemplifica las métricas más importantes para evaluar modelos de:\n",
        "\n",
        "- Clasificación (binaria o multiclase)\n",
        "- Regresión\n",
        "\n",
        "Usamos ejemplos prácticos con sklearn y matplotlib para visualizar cómo se comportan las métricas.\n"
      ],
      "metadata": {
        "id": "LT6Z5zQu0tOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clasificación - Métricas clave"
      ],
      "metadata": {
        "id": "E7EPn-BJ1VUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Cargar y preparar el dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Preprocesamiento similar al notebook anterior\n",
        "df = df.drop(columns=['deck', 'embark_town', 'alive'])\n",
        "df['age'] = df['age'].fillna(df['age'].median())\n",
        "df['embarked'] = df['embarked'].fillna(df['embarked'].mode()[0])\n",
        "df['sex'] = df['sex'].map({'male': 0, 'female': 1})\n",
        "df = pd.get_dummies(df, columns=['embarked'], drop_first=True)\n",
        "\n",
        "# Crear nuevas variables\n",
        "df['family_size'] = df['sibsp'] + df['parch'] + 1\n",
        "df['is_alone'] = (df['family_size'] == 1).astype(int)\n",
        "\n",
        "# Escalar\n",
        "scaler = StandardScaler()\n",
        "df[['age', 'fare']] = scaler.fit_transform(df[['age', 'fare']])\n",
        "\n",
        "# Selección de variables\n",
        "features = ['pclass', 'sex', 'age', 'fare', 'family_size', 'is_alone', 'embarked_Q', 'embarked_S']\n",
        "X = df[features]\n",
        "y = df['survived']\n",
        "\n",
        "# División de datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "FvDJL5yx5Fnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WBpcaFWyXbk"
      },
      "outputs": [],
      "source": [
        "# Obtenemos el dataset del Titanic\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay\n",
        "\n",
        "# Entrenamiento rápido\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilidades para ROC AUC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
      ],
      "metadata": {
        "id": "didtkmXr10RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de confusión\n",
        "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)"
      ],
      "metadata": {
        "id": "7Bp3XGLs2Cib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ¿Cuándo usar cada métrica de clasificación?\n",
        "\n",
        "| Métrica    | ¿Qué mide?                                 | Cuándo usarla                              |\n",
        "|------------|---------------------------------------------|--------------------------------------------|\n",
        "| **Accuracy**   | Porcentaje de predicciones correctas                | Cuando las clases están balanceadas              |\n",
        "| **Precision**  | % de positivos predichos que son correctos | Si quieres evitar falsos positivos (ej: spam) |\n",
        "| **Recall**     | % de verdaderos positivos capturados       | Si no quieres perder ningún positivo (ej: cáncer) |\n",
        "| **F1 Score**   | Media armónica de precision y recall       | Si quieres equilibrio entre ambos          |\n",
        "| **ROC AUC**    | Capacidad del modelo de discriminar entre clases                | Para comparar clasificadores en general |\n"
      ],
      "metadata": {
        "id": "f-QjDYsi4B3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión - Métricas clave"
      ],
      "metadata": {
        "id": "WwHmhS3R2NS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Partimos de un nuevo dataset, Boston Housing: fetch_california_housing()"
      ],
      "metadata": {
        "id": "JH00vclx2hrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "zSgvh0rX2IHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
        "print(\"R2 Score:\", r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "pNDBu6Al2rkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ¿Cuándo usar cada métrica de regresión?\n",
        "\n",
        "| Métrica    | ¿Qué mide?                                  | Cuándo usarla                              |\n",
        "|------------|----------------------------------------------|--------------------------------------------|\n",
        "| **MAE**        | Error medio absoluto                         | Fácil de interpretar, útil si te importan los errores medios |\n",
        "| **RMSE**       | Error cuadrático medio (penaliza errores grandes) | Si quieres penalizar mucho los errores grandes      |\n",
        "| **R² Score**         | Porcentaje de varianza explicada por el modelo       | Para evaluar calidad general del modelo en su conjunto           |\n"
      ],
      "metadata": {
        "id": "q2Aow1BJ4J-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualización del ajuste (Predicción - Realidad)"
      ],
      "metadata": {
        "id": "4BtmkPJh3Bvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Valores reales')\n",
        "plt.ylabel('Predicciones')\n",
        "plt.title('Predicciones vs Realidad')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3dyCnaoz2ujw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusión"
      ],
      "metadata": {
        "id": "lOLcRLCA3YYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elegir la métrica correcta depende del objetivo del problema:\n",
        "\n",
        "- Clasificación médica: **Recall** > Precision\n",
        "- Detección de fraude: **Precision** > Recall\n",
        "- Clasificación general: **F1 Score**\n",
        "- Comparar modelos: **ROC AUC**\n",
        "\n",
        "En regresión:\n",
        "- MAE si te importan errores medios\n",
        "- RMSE si penalizas mucho los errores grandes\n",
        "- R² si quieres ver cuánta variabilidad estás explicando\n"
      ],
      "metadata": {
        "id": "Orm1S9f93T-X"
      }
    }
  ]
}