{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HlwEmy-Tjd9-",
        "c4feWHsklkaL",
        "vA6gmIKQleO_",
        "cX_XIuS_gkgI",
        "WpD7ObMmjWLN",
        "FKy7bHORm5xG"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üßº Data Preprocessing Techniques\n",
        "\n",
        "Este notebook explora t√©cnicas esenciales de **preprocesamiento de datos**, una etapa clave en cualquier proyecto de ciencia de datos o aprendizaje autom√°tico.\n",
        "\n",
        "> El objetivo es preparar los datos para que los modelos de machine learning funcionen de forma eficiente y precisa.\n"
      ],
      "metadata": {
        "id": "v_p1zEOqlBA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datos de ejemplo"
      ],
      "metadata": {
        "id": "HlwEmy-Tjd9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importaci√≥n de librer√≠as"
      ],
      "metadata": {
        "id": "Fpcevdaalhq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importaci√≥n de librerias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n"
      ],
      "metadata": {
        "id": "GG3MVM8_lKOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Carga de datos de ejemplo"
      ],
      "metadata": {
        "id": "c4feWHsklkaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos un DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'Edad': [25, 27, np.nan, 35, 29],\n",
        "    'Salario': [50000, 54000, 58000, np.nan, 62000],\n",
        "    'Ciudad': ['Madrid', 'Barcelona', 'Madrid', 'Valencia', np.nan]\n",
        "})\n",
        "\n",
        "data\n"
      ],
      "metadata": {
        "id": "Th9Yay2UlKuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Manejo de valores faltantes\n",
        "\n",
        "Los valores faltantes pueden sesgar resultados o hacer que los modelos no funcionen. Existen varias estrategias:\n",
        "- Eliminar filas/columnas con muchos valores faltantes\n",
        "- Imputar (rellenar) con la media, mediana, moda, o valores espec√≠ficos\n"
      ],
      "metadata": {
        "id": "vA6gmIKQleO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = SimpleImputer(strategy='mean')\n",
        "data[['Edad', 'Salario']] = imputer.fit_transform(data[['Edad', 'Salario']])\n",
        "data\n"
      ],
      "metadata": {
        "id": "m4_TJjdilenn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Codificaci√≥n de variables categ√≥ricas\n",
        "\n",
        "Los modelos no pueden trabajar con texto. Las variables categ√≥ricas deben transformarse en n√∫meros.\n",
        "- Label Encoding\n",
        "- One-Hot Encoding\n"
      ],
      "metadata": {
        "id": "cX_XIuS_gkgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "encoded = encoder.fit_transform(data[['Ciudad']])\n",
        "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(['Ciudad']))\n",
        "\n",
        "# Unimos al dataset original\n",
        "data = data.drop('Ciudad', axis=1)\n",
        "data = pd.concat([data, encoded_df], axis=1)\n",
        "data\n"
      ],
      "metadata": {
        "id": "ry2XRvAhgk92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Escalado de caracter√≠sticas num√©ricas\n",
        "\n",
        "Muchas t√©cnicas de ML se ven afectadas por la escala de los datos. Por ejemplo, KNN o regresi√≥n log√≠stica.\n",
        "\n",
        "- `StandardScaler`: media 0, varianza 1\n",
        "- `MinMaxScaler`: valores entre 0 y 1\n"
      ],
      "metadata": {
        "id": "Kh6xdGQ9gtYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "data[['Edad', 'Salario']] = scaler.fit_transform(data[['Edad', 'Salario']])\n",
        "data\n"
      ],
      "metadata": {
        "id": "EJglKYEagtx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing Techniques with Real Data\n",
        "\n",
        "A continuaci√≥n veremos paso a paso c√≥mo preparar datos reales para un modelo de machine learning. Usaremos el dataset de pasajeros del Titanic, que contiene datos como edad, clase social, g√©nero, etc.\n",
        "\n",
        "> El objetivo es aplicar transformaciones necesarias para que los modelos puedan entender y procesar la informaci√≥n correctamente.\n"
      ],
      "metadata": {
        "id": "WpD7ObMmjWLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Librer√≠as para manipulaci√≥n de datos y visualizaci√≥n\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns  # para cargar dataset y visualizar\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Librer√≠as para preprocesamiento\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n"
      ],
      "metadata": {
        "id": "5N4SKwWrjVkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el dataset del Titanic desde seaborn\n",
        "df = sns.load_dataset(\"titanic\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "s6OyQvIikLhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensiones y tipos\n",
        "print(df.shape)\n",
        "print(df.dtypes)\n",
        "\n",
        "# Ver cu√°ntos valores faltantes hay por columna\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "Xj1hEtPkk54a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Vemos que hay columnas con muchos valores faltantes, como `deck`, y otras con algunos, como `age` y `embarked`.\n"
      ],
      "metadata": {
        "id": "qg_h1fnVk9Sj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A. Separar variables num√©ricas y categ√≥ricas\n",
        "\n",
        "# Selecci√≥n b√°sica de columnas √∫tiles\n",
        "df_model = df[['survived', 'pclass', 'sex', 'age', 'embarked']].copy()\n",
        "\n",
        "# Identificamos variables num√©ricas y categ√≥ricas\n",
        "numerical_features = ['age']\n",
        "categorical_features = ['pclass', 'sex', 'embarked']"
      ],
      "metadata": {
        "id": "e2qzmFW4lITc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# B. Definir transformaciones para cada tipo de dato\n",
        "\n",
        "# Imputaci√≥n de valores num√©ricos + escalado\n",
        "numerical_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),  # reemplaza nulos por mediana\n",
        "    ('scaler', StandardScaler())                    # estandariza la escala\n",
        "])\n",
        "\n",
        "# Imputaci√≥n + one-hot encoding para categ√≥ricas\n",
        "categorical_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),   # modo (valor m√°s com√∫n)\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))     # one-hot para texto\n",
        "])"
      ],
      "metadata": {
        "id": "qBBBoaTblTzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C. Combinar todo con ColumnTransformer\n",
        "\n",
        "# Aplicamos transformaciones diferentes a cada tipo de columna\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numerical_pipeline, numerical_features),\n",
        "    ('cat', categorical_pipeline, categorical_features)\n",
        "])"
      ],
      "metadata": {
        "id": "Iy6BSqPblqlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicamos el preprocesamiento al dataset\n",
        "X = df_model.drop('survived', axis=1)\n",
        "y = df_model['survived']\n",
        "\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Convertimos el resultado a DataFrame para visualizar\n",
        "X_preprocessed_df = pd.DataFrame(\n",
        "    X_preprocessed.toarray() if hasattr(X_preprocessed, 'toarray') else X_preprocessed,\n",
        "    columns=preprocessor.get_feature_names_out()\n",
        ")\n",
        "\n",
        "X_preprocessed_df.head()"
      ],
      "metadata": {
        "id": "y6JcRo7WmGxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úÖ Resumen:\n",
        "\n",
        "- C√≥mo cargar datos reales con valores faltantes y tipos mixtos\n",
        "- C√≥mo construir pipelines de preprocesamiento con `scikit-learn`\n",
        "- La importancia de separar transformaciones para num√©ricos y categ√≥ricos\n",
        "- Aplicar `ColumnTransformer` para organizar el flujo de limpieza\n",
        "\n",
        "Este tipo de flujo es muy com√∫n en pipelines reales, sobre todo al trabajar con `sklearn`, `MLFlow` o producci√≥n.\n"
      ],
      "metadata": {
        "id": "aCU0aV1LmTXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (ANEXO) Exploratory Data Analysis (EDA)\n",
        "\n",
        "Antes de cualquier transformaci√≥n o modelado, es fundamental entender el dataset: su estructura, patrones, valores extremos, datos faltantes, y distribuciones.\n",
        "\n",
        "Exploraremos:\n",
        "\n",
        "1. Informaci√≥n general del dataset\n",
        "2. An√°lisis de valores faltantes\n",
        "3. Estad√≠sticas b√°sicas\n",
        "4. Distribuci√≥n de variables\n",
        "5. Correlaciones y relaciones clave\n"
      ],
      "metadata": {
        "id": "FKy7bHORm5xG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Info general del dataset\n",
        "\n",
        "# N√∫mero de filas y columnas\n",
        "print(f\"Shape: {df.shape}\")\n",
        "\n",
        "# Tipos de datos y no nulos\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "Q9Liq4knm8D3",
        "outputId": "85a2de90-a351-41e3-c941-fb24ccf9ad00"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c2a90c55cdf6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# N√∫mero de filas y columnas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape: {df.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Tipos de datos y no nulos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Valores faltantes visuales\n",
        "\n",
        "import missingno as msno\n",
        "\n",
        "# Visualizaci√≥n r√°pida de nulos\n",
        "msno.matrix(df)\n",
        "\n",
        "# Total de valores nulos por columna\n",
        "df.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "4KDoz_hVnU2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Estad√≠sticas b√°sicas por tipo de variable\n",
        "\n",
        "# Variables num√©ricas\n",
        "df.describe()\n",
        "\n",
        "# Variables categ√≥ricas\n",
        "df.describe(include='object')"
      ],
      "metadata": {
        "id": "ZYzA4982nfng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Distribuciones importantes (dataset del Titanic)\n",
        "\n",
        "# Distribuci√≥n de la edad\n",
        "sns.histplot(df['age'], kde=True)\n",
        "plt.title('Distribuci√≥n de Edad')\n",
        "plt.show()\n",
        "\n",
        "# Supervivencia por sexo\n",
        "sns.countplot(data=df, x='sex', hue='survived')\n",
        "plt.title('Supervivencia por Sexo')\n",
        "plt.show()\n",
        "\n",
        "# Distribuci√≥n de clases y supervivencia\n",
        "sns.countplot(data=df, x='pclass', hue='survived')\n",
        "plt.title('Supervivencia por Clase Social')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OJq2sIrynwSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Correlaciones entre variables num√©ricas\n",
        "\n",
        "# Matriz de correlaci√≥n\n",
        "correlation = df.select_dtypes(include='number').corr()\n",
        "\n",
        "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
        "plt.title('Matriz de Correlaci√≥n')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pj21iLHJoBJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Otras opciones son:\n",
        "# Boxplots para ver outliers por grupo\n",
        "# Pairplots para ver relaciones entre m√∫ltiples variables\n",
        "# Violin plots si quieres distribuci√≥n + densidad\n",
        "# pivot_table()\tCruce entre 2 variables\n",
        "# value_counts()\tFrecuencia de categor√≠as\n",
        "\n",
        "\n",
        "# Boxplot: edad por clase\n",
        "sns.boxplot(data=df, x='pclass', y='age')\n",
        "plt.title('Distribuci√≥n de Edad por Clase')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VwbGJBbioHyj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}